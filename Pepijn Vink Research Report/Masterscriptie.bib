@article{allison2017,
  title = {Maximum {{Likelihood}} for {{Cross-lagged Panel Models}} with {{Fixed Effects}}},
  author = {Allison, Paul D. and Williams, Richard and {Moral-Benito}, Enrique},
  year = {2017},
  month = jan,
  journal = {Socius},
  volume = {3},
  pages = {2378023117710578},
  publisher = {{SAGE Publications}},
  issn = {2378-0231},
  doi = {10.1177/2378023117710578},
  urldate = {2023-11-28},
  abstract = {Panel data make it possible both to control for unobserved confounders and allow for lagged, reciprocal causation. Trying to do both at the same time, however, leads to serious estimation difficulties. In the econometric literature, these problems have been solved by using lagged instrumental variables together with the generalized method of moments (GMM). Here we show that the same problems can be solved by maximum likelihood (ML) estimation implemented with standard software packages for structural equation modeling (SEM). Monte Carlo simulations show that the ML-SEM method is less biased and more efficient than the GMM method under a wide range of conditions. ML-SEM also makes it possible to test and relax many of the constraints that are typically embodied in dynamic panel models.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/RP945UTP/Allison et al. - 2017 - Maximum Likelihood for Cross-lagged Panel Models w.pdf}
}

@article{andersen2021,
  title = {Equivalent {{Approaches}} to {{Dealing}} with {{Unobserved Heterogeneity}} in {{Cross-Lagged Panel Models}}?},
  author = {Andersen, Henrik Kenneth},
  year = {2021},
  abstract = {Panel models in structural equation modeling that combine static and dynamic components make it possible to investigate reciprocal relations while controlling for time-invariant unobserved heterogeneity. Recently, the Latent Curve Model with Structured Residuals and the Random-Intercept Cross-Lagged Panel Model were suggested as `residual-level' versions of the more traditional Autoregressive Latent Trajectory and Dynamic Panel Models, respectively. Their main benefit is that they allow for a more straightforward interpretation of the trajectory factors. It is not widely known, however, that the residuallevel models place potentially strong assumptions on the initial conditions, i.e., the process that was occurring before the observation period began. If the process under investigation is not both stationary and at equilibrium then the residual-level models are not appropriate. They then do not control for all time-invariant unobserved heterogeneity and can result in biased cross-lagged and autoregressive estimates. I demonstrate this using the problem behavior of cigarette smoking amongst adolescents: because the mean and variance of this process changes as a young person's smoking behavior develops, early stages of this process should not be examined using the residual-level models. This issue potentially exists for a wide variety of psychological and sociological topics, essentially whenever the process under investigation is changing over the course of the observation period. This paper discusses strategies to help researchers decide which model to use when, and compares some of their relative advantages and drawbacks. An amendment to the residual-level models is suggested in which the latent individual effects are allowed to covary with the initial residuals. This makes the residual-level models robust to violations of the assumptions surrounding the initial conditions, while retaining their other beneficial aspects.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/PG47GZGK/Andersen - Equivalent Approaches to Dealing with Unobserved H.pdf}
}

@article{bollen2004,
  title = {Autoregressive {{Latent Trajectory}} ({{ALT}}) {{Models A Synthesis}} of {{Two Traditions}}},
  author = {Bollen, Kenneth A. and Curran, Patrick J.},
  year = {2004},
  journal = {Sociological Methods \& Research},
  volume = {32},
  number = {3},
  pages = {336--383},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/0049124103260222},
  urldate = {2023-09-08},
  abstract = {Although there are a variety of statistical methods available for the analysis of longitudinal panel data, two approaches are of particular historical importance: the autoregressive (simplex) model and the latent trajectory (curve) model. These two approaches have been portrayed as competing methodologies such that one approach is superior to the other. We argue that the autoregressive and trajectory models are special cases of a more encompassing model that we call the autoregressive latent trajectory (ALT) model. In this paper we detail the underlying statistical theory and mathematical identification of this model, and demonstrate the ALT model using two empirical data sets. The first reanalyzes a simulated repeated measures data set that was previously used to argue against the autoregressive model, and we illustrate how the ALT model can recover the true latent curve model. Second, we apply the ALT model to real family income data on N=3912 adults over a seven year period and find evidence for both autoregressive and latent trajectory processes. Extensions and limitations are discussed.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/DBZIKZC2/Bollen and Curran - 2004 - Autoregressive Latent Trajectory (ALT) Models A Sy.pdf}
}

@article{bollen2010,
  title = {A {{General Panel Model}} with {{Random}} and {{Fixed Effects}}: {{A Structural Equations Approach}}},
  shorttitle = {A {{General Panel Model}} with {{Random}} and {{Fixed Effects}}},
  author = {Bollen, K. A. and Brand, J. E.},
  year = {2010},
  month = sep,
  journal = {Social Forces},
  volume = {89},
  number = {1},
  pages = {1--34},
  issn = {0037-7732, 1534-7605},
  doi = {10.1353/sof.2010.0072},
  urldate = {2023-11-28},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/B5GTTWYV/Bollen and Brand - 2010 - A General Panel Model with Random and Fixed Effect.pdf}
}

@article{brown2021,
  title = {Propensity Score Stratification Methods for Continuous Treatments},
  author = {Brown, Derek W. and Greene, Thomas J. and Swartz, Michael D. and Wilkinson, Anna V. and DeSantis, Stacia M.},
  year = {2021},
  journal = {Statistics in Medicine},
  volume = {40},
  number = {5},
  pages = {1189--1203},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.8835},
  abstract = {Continuous treatments propensity scoring remains understudied as the majority of methods are focused on the binary treatment setting. Current propensity score methods for continuous treatments typically rely on weighting in order to produce causal estimates. It has been shown that in some continuous treatment settings, weighting methods can result in worse covariate balance than had no adjustments been made to the data. Furthermore, weighting is not always stable, and resultant estimates may be unreliable due to extreme weights. These issues motivate the current development of novel propensity score stratification techniques to be used with continuous treatments. Specifically, the generalized propensity score cumulative distribution function (GPS-CDF) and the nonparametric GPS-CDF approaches are introduced. Empirical CDFs are used to stratify subjects based on pretreatment confounders in order to produce causal estimates. A detailed simulation study shows superiority of these new stratification methods based on the empirical CDF, when compared with standard weighting techniques. The proposed methods are applied to the ``Mexican-American Tobacco use in Children'' study to determine the causal relationship between continuous exposure to smoking imagery in movies, and smoking behavior among Mexican-American adolescents. These promising results provide investigators with new options for implementing continuous treatment propensity scoring.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/Q5EJTM33/Brown et al. - 2021 - Propensity score stratification methods for contin.pdf}
}

@article{guo2020,
  title = {Propensity {{Score Analysis}}: {{Recent Debate}} and {{Discussion}}},
  shorttitle = {Propensity {{Score Analysis}}},
  author = {Guo, Shenyang and Fraser, Mark and Chen, Qi},
  year = {2020},
  journal = {Journal of the Society for Social Work and Research},
  volume = {11},
  number = {3},
  pages = {463--482},
  doi = {10.1086/711393},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/4A7KJ29E/Propensity Score Analysis Recent Debate and Discu.pdf;/Users/pepijnvink/Zotero/storage/2MVL8Y9K/711393.html}
}

@article{haber2022,
  title = {Causal and {{Associational Language}} in {{Observational Health Research}}: {{A Systematic Evaluation}}},
  shorttitle = {Causal and {{Associational Language}} in {{Observational Health Research}}},
  author = {Haber, Noah A and Wieten, Sarah E and Rohrer, Julia M and Arah, Onyebuchi A and Tennant, Peter W G and Stuart, Elizabeth A and Murray, Eleanor J and Pilleron, Sophie and Lam, Sze Tung and Riederer, Emily and Howcutt, Sarah Jane and Simmons, Alison E and Leyrat, Cl{\'e}mence and Schoenegger, Philipp and Booman, Anna and Dufour, Mi-Suk Kang and O'Donoghue, Ashley L and Baglini, Rebekah and Do, Stefanie and Takashima, Mari De La Rosa and Evans, Thomas Rhys and {Rodriguez-Molina}, Daloha and Alsalti, Taym M and Dunleavy, Daniel J and {Meyerowitz-Katz}, Gideon and Antonietti, Alberto and Calvache, Jose A and Kelson, Mark J and Salvia, Meg G and Parra, Camila Olarte and {Khalatbari-Soltani}, Saman and McLinden, Taylor and Chatton, Arthur and Seiler, Jessie and Steriu, Andreea and Alshihayb, Talal S and Twardowski, Sarah E and Dabravolskaj, Julia and Au, Eric and Hoopsick, Rachel A and Suresh, Shashank and Judd, Nicholas and Pe{\~n}a, Sebasti{\'a}n and Axfors, Cathrine and Khan, Palwasha and Rivera Aguirre, Ariadne E and Odo, Nnaemeka U and Schmid, Ian and Fox, Matthew P},
  year = {2022},
  journal = {American Journal of Epidemiology},
  volume = {191},
  number = {12},
  pages = {2084--2097},
  issn = {0002-9262, 1476-6256},
  doi = {10.1093/aje/kwac137},
  abstract = {Abstract             We estimated the degree to which language used in the high-profile medical/public health/epidemiology literature implied causality using language linking exposures to outcomes and action recommendations; examined disconnects between language and recommendations; identified the most common linking phrases; and estimated how strongly linking phrases imply causality. We searched for and screened 1,170 articles from 18 high-profile journals (65 per journal) published from 2010{\textendash}2019. Based on written framing and systematic guidance, 3 reviewers rated the degree of causality implied in abstracts and full text for exposure/outcome linking language and action recommendations. Reviewers rated the causal implication of exposure/outcome linking language as none (no causal implication) in 13.8\%, weak in 34.2\%, moderate in 33.2\%, and strong in 18.7\% of abstracts. The implied causality of action recommendations was higher than the implied causality of linking sentences for 44.5\% or commensurate for 40.3\% of articles. The most common linking word in abstracts was ``associate'' (45.7\%). Reviewers' ratings of linking word roots were highly heterogeneous; over half of reviewers rated ``association'' as having at least some causal implication. This research undercuts the assumption that avoiding ``causal'' words leads to clarity of interpretation in medical research.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/9A8WRKXY/Haber et al. - 2022 - Causal and Associational Language in Observational.pdf}
}

@article{hamaker2005,
  title = {Conditions for the {{Equivalence}} of the {{Autoregressive Latent Trajectory Model}} and a {{Latent Growth Curve Model With Autoregressive Disturbances}}},
  author = {Hamaker, Ellen L.},
  year = {2005},
  journal = {Sociological Methods \& Research},
  volume = {33},
  number = {3},
  pages = {404--416},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/0049124104270220},
  abstract = {Curran and Bollen combined two models for longitudinal panel data: the latent growth curve model and the autoregressive model. In their model, the autoregressive relationships are modeled between the observed variables. This is a different model than a latent growth curve model with autoregressive relationships between the disturbances. However, when the autoregressive parameter is invariant over time and lies between-1 and 1, it can be shown that these models are algebraically equivalent. This result can be shown to generalize to the multivariate case. When the autoregressive parameters in the autoregressive latent trajectory model vary over time, the equivalence between the autoregressive latent trajectory model and a latent growth curve model with autoregressive disturbances no longer holds. However, a latent growth curve model with time-varying autoregressive parameters for the disturbances could be considered an interesting alternative to the autoregressive latent trajectory model with time-varying autoregressive parameters.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/NE34KPN7/Hamaker - 2005 - Conditions for the Equivalence of the Autoregressi.pdf}
}

@article{hamaker2015,
  title = {A Critique of the Cross-Lagged Panel Model.},
  author = {Hamaker, Ellen L. and Kuiper, Rebecca M. and Grasman, Raoul P. P. P.},
  year = {2015},
  journal = {Psychological Methods},
  volume = {20},
  number = {1},
  pages = {102--116},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0038889},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/XR39FKAM/Hamaker et al. - 2015 - A critique of the cross-lagged panel model..pdf}
}

@article{hoffman2024,
  title = {Considering Between- and within-Person Relations in Auto-Regressive Cross-Lagged Panel Models for Developmental Data},
  author = {Hoffman, Lesa and Hall, Garret J.},
  year = {2024},
  month = feb,
  journal = {Journal of School Psychology},
  volume = {102},
  pages = {101258},
  issn = {0022-4405},
  doi = {10.1016/j.jsp.2023.101258},
  urldate = {2023-12-19},
  abstract = {Longitudinal data can provide inferences at both the between-person and within-person levels of analysis, but only to the extent that the statistical models chosen for data analysis are specified to adequately capture these distinct sources of association. The present work focuses on auto-regressive cross-lagged panel models, which have long been used to examine time-lagged reciprocal relations and mediation among multiple variables measured repeatedly over time. Unfortunately, many common implementations of these models fail to distinguish between-person associations among individual differences in the variables' amounts and changes over time, and thus confound between-person and within-person relations either partially or entirely, leading to inaccurate results. Furthermore, in the increasingly complex model variants that continue to be developed, what is not easily appreciated is how substantial differences in interpretation can be created by what appear to be trivial differences in model specification. In the present work, we aimed to (a) help analysts become better acquainted with the some of the more common model variants that fall under this larger umbrella, and (b) explicate what characteristics of one's data and research questions should be considered in selecting a model. Supplementary Materials include annotated model syntax and output using Mplus, lavaan in R, and sem in Stata to help translate these concepts into practice.},
  keywords = {Latent curve model,Longitudinal structural equation modeling,Random intercept cross-lagged panel model,Reciprocal relations,Smushed effects,Structured residuals},
  file = {/Users/pepijnvink/Zotero/storage/7EWWDEF6/S0022440523000869.html}
}

@article{lavaan,
  title = {\{lavaan\}: {{An}} \{\vphantom\}{{R}}\vphantom\{\} {{Package}} for {{Structural Equation Modeling}}},
  author = {Rosseel, Yves},
  year = {2012},
  journal = {Journal of Statistical Software},
  volume = {48},
  number = {2},
  pages = {1--36},
  doi = {10.18637/jss.v048.i02}
}

@article{leite2019,
  title = {Propensity {{Score Analysis}} of {{Complex Survey Data}} with {{Structural Equation Modeling}}: {{A Tutorial}} with {{Mplus}}},
  shorttitle = {Propensity {{Score Analysis}} of {{Complex Survey Data}} with {{Structural Equation Modeling}}},
  author = {Leite, Walter L. and Stapleton, Laura M. and Bettini, Elizabeth F.},
  year = {2019},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {26},
  number = {3},
  pages = {448--469},
  issn = {1070-5511},
  doi = {10.1080/10705511.2018.1522591},
  abstract = {Propensity score (PS) analysis aims to reduce bias in treatment effect estimates obtained from observational studies, which may occur due to non-random differences between treated and untreated groups with respect to covariates related to the outcome. We demonstrate how to use structural equation modeling (SEM) for PS analysis to remove selection bias due to latent covariates and estimate treatment effects on latent outcomes. Following the discussion of the design and analysis stages of PS analysis with SEM, an example is presented which uses the Mplus software to analyze data from the 1999 School and Staffing Survey (SASS) and 2000 Teacher Follow-up Survey (TFS) to estimate the effects teacher's participation in a network of teachers on the teacher's perception of workload manageability.},
  keywords = {causal inference,latent confounders,potential outcomes framework,propensity score analysis,propensity score weighting,Rubin's Causal model,sensitivity analysis,structural equation modeling},
  file = {/Users/pepijnvink/Zotero/storage/ES2QCYGY/Leite et al. - 2019 - Propensity Score Analysis of Complex Survey Data w.pdf}
}

@article{lucas2023,
  title = {Why the {{Cross-Lagged Panel Model Is Almost Never}} the {{Right Choice}}},
  author = {Lucas, Richard E.},
  year = {2023},
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {6},
  number = {1},
  pages = {1--22},
  issn = {2515-2459},
  doi = {10.1177/25152459231158378},
  abstract = {The cross-lagged panel model (CLPM) is a widely used technique for examining reciprocal causal effects using longitudinal data. Critics of the CLPM have noted that by failing to account for certain person-level associations, estimates of these causal effects can be biased. Because of this, models that incorporate stable-trait components (e.g., the random-intercept CLPM) have become popular alternatives. Debates about the merits of the CLPM have continued, however, with some researchers arguing that the CLPM is more appropriate than modern alternatives for examining common psychological questions. In this article, I discuss the ways that these defenses of the CLPM fail to acknowledge well-known limitations of the model. I propose some possible sources of confusion regarding these models and provide alternative ways of thinking about the problems with the CLPM. I then show in simulated data that with realistic assumptions, the CLPM is very likely to find spurious cross-lagged effects when they do not exist and can sometimes underestimate these effects when they do exist.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/6RHIMDE6/Lucas - 2023 - Why the Cross-Lagged Panel Model Is Almost Never t.pdf}
}

@misc{ludtke2021,
  type = {Preprint},
  title = {A {{Critique}} of the {{Random Intercept Cross-Lagged Panel Model}}},
  author = {L{\"u}dtke, Oliver and Robitzsch, Alexander},
  year = {2021},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/6f85c},
  abstract = {The random intercept cross-lagged panel model (RI-CLPM) is an extension of the traditional cross-lagged panel model (CLPM) that allows controlling for stable trait factors when estimating cross-lagged effects. It has been argued that the RI-CLPM more appropriately accounts for trait-like, timeinvariant stability of many psychological constructs and that it should be preferred over the CLPM when at least three waves of measurement are available. The basic idea of the RI-CLPM is to decompose longitudinal associations between two constructs into stable between-person associations and temporal within-person dynamics. The present article critically examines the RI-CLPM from a causal inference perspective. Using formal analysis and simulated data, we show that the RI-CLPM has limited potential to control for unobserved stable confounder variables when estimating crosslagged effects. The CLPM with additional lag-2 effects sufficiently controls for delayed effects, as long as all relevant covariates are measured. Furthermore, we clarify that, in general, the RI-CLPM targets a different causal estimand than the CLPM. Whereas the cross-lagged effect in the CLPM targets the effect of increasing the exposure by one unit, the within-person cross-lagged effect in the RI-CLPM provides an estimate of the effect of increasing the exposure by one unit around the person mean. We argue that this within-person causal effect is typically less relevant for testing causal hypotheses with longitudinal data because it only captures temporary fluctuations around the individual person means and ignores the potential effects of causes that explain differences between persons.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/GMWR9FTR/Lüdtke and Robitzsch - 2021 - A Critique of the Random Intercept Cross-Lagged Pa.pdf}
}

@article{ludtke2022,
  title = {A {{Comparison}} of {{Different Approaches}} for {{Estimating Cross-Lagged Effects}} from a {{Causal Inference Perspective}}},
  author = {L{\"u}dtke, Oliver and Robitzsch, Alexander},
  year = {2022},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {29},
  number = {6},
  pages = {888--907},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2022.2065278},
  abstract = {This article compares different approaches for estimating cross-lagged effects with a cross-lagged panel design under a causal inference perspective. We distinguish between models that rely on no unmeasured confounding (i.e., observed covariates are sufficient to remove confounding) and latent variable-type models (e.g., random intercept cross-lagged panel model) that use parametric assumptions to adjust for unmeasured time-invariant confounding by including additional latent variables. Simulation studies confirm that the cross-lagged panel model provides biased estimates of the crosslagged effect in the presence of unmeasured confounding. However, the simulations also show that the latent variable-type approaches strongly depend on the specific parametric assumptions, and produce biased estimates under different data-generating scenarios. Finally, we discuss the role of the longitudinal design and the limitations of assessing model fit for estimating cross-lagged effects.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/FN676GIR/Lüdtke and Robitzsch - 2022 - A Comparison of Different Approaches for Estimatin.pdf}
}

@article{moerkerke2015,
  title = {Structural Equation Modeling versus Marginal Structural Modeling for Assessing Mediation in the Presence of Posttreatment Confounding.},
  author = {Moerkerke, Beatrijs and Loeys, Tom and Vansteelandt, Stijn},
  year = {2015},
  journal = {Psychological Methods},
  volume = {20},
  number = {2},
  pages = {204--220},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0036368},
  abstract = {Inverse probability weighting for marginal structural models has been suggested as a strategy to estimate the direct effect of a treatment or exposure on an outcome in studies where the effect of mediator on outcome is subject to posttreatment confounding. This type of confounding, whereby confounders of the effect of mediator on outcome are themselves affected by the exposure, complicates mediation analyses and necessitates apt analysis strategies. In this article, we contrast the inverse probability weighting approach with the traditional path analysis approach to mediation analysis. We show that in a particular class of linear models, adjustment for posttreatment confounding can be realized via a fairly standard modification of the traditional path analysis approach. The resulting approach is simpler; by avoiding inverse probability weighting, it moreover results in direct effect estimators with smaller finite sample bias and greater precision. We further show that a particular variant of the G-estimation approach from the causal inference literature is equivalent with the path analysis approach in simple linear settings but is more generally applicable in settings with interactions and/or noncontinuous mediators and confounders. We conclude that the use of inverse probability weighting for marginal structural models to adjust for posttreatment confounding in mediation analysis is primarily indicated in nonlinear models for the outcome.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/3MMRK5ZE/Moerkerke et al. - 2015 - Structural equation modeling versus marginal struc.pdf}
}

@article{morris2019,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  year = {2019},
  journal = {Statistics in Medicine},
  volume = {38},
  number = {11},
  pages = {2074--2102},
  issn = {1097-0258},
  doi = {10.1002/sim.8086},
  urldate = {2023-11-13},
  abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some ``truth'' (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (``ADEMP''); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
  copyright = {{\textcopyright} 2019 The Authors. Statistics~in~Medicine Published by John Wiley \& Sons Ltd.},
  langid = {english},
  keywords = {graphics for simulation,Monte Carlo,simulation design,simulation reporting,simulation studies},
  file = {/Users/pepijnvink/Zotero/storage/9NS2XP7A/Morris et al. - 2019 - Using simulation studies to evaluate statistical m.pdf;/Users/pepijnvink/Zotero/storage/A2G2F7YK/sim.html}
}

@article{mulder2021,
  title = {Three {{Extensions}} of the {{Random Intercept Cross-Lagged Panel Model}}},
  author = {Mulder, Jeroen D. and Hamaker, Ellen L.},
  year = {2021},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {28},
  number = {4},
  pages = {638--648},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2020.1784738},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/UWUVBEEM/Mulder and Hamaker - 2021 - Three Extensions of the Random Intercept Cross-Lag.pdf}
}

@article{mulder2023,
  title = {Power {{Analysis}} for the {{Random Intercept Cross-Lagged Panel Model Using}} the {{powRICLPM R-Package}}},
  author = {Mulder, Jeroen D.},
  year = {2023},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {30},
  number = {4},
  pages = {645--658},
  issn = {1070-5511},
  doi = {10.1080/10705511.2022.2122467},
  abstract = {The random intercept cross-lagged panel model (RI-CLPM) is a popular model among psychologists for studying reciprocal effects in longitudinal panel data. Although various texts and software packages have been published concerning power analyses for structural equation models (SEM) generally, none have proposed a power analysis strategy that is tailored to the particularities of the RI-CLPM. This can be problematic because mismatches between the power analysis design, the model, and reality, can negatively impact the validity of the recommended sample size and number of repeated measures. As power analyses play an increasingly important role in the preparation phase of research projects, an RI-CLPM-specific strategy for the design of a power analysis is detailed, and implemented in the R-package powRICLPM. This paper focuses on the (basic) bivariate RI-CLPM, and extensions to include constraints over time, measurement error (leading to the stable trait autoregressive trait state model), non-normal data, and bounded estimation.},
  keywords = {Power,R-package,random intercept cross-lagged panel model,stable trait autoregressive trait state model},
  file = {/Users/pepijnvink/Zotero/storage/UUAJZFLP/Mulder - 2023 - Power Analysis for the Random Intercept Cross-Lagg.pdf}
}

@techreport{murayama2022,
  type = {Preprint},
  title = {Thinking Clearly about Time-Invariant Confounders in Cross-Lagged Panel Models: {{A}} Guide for Choosing a Statistical Model from a Causal Inference Perspective},
  shorttitle = {Thinking Clearly about Time-Invariant Confounders in Cross-Lagged Panel Models},
  author = {Murayama, Kou and Gfr{\"o}rer, Thomas},
  year = {2022},
  institution = {{PsyArXiv}},
  abstract = {Many statistical models have been proposed to examine reciprocal cross-lagged causal effects from panel data. The present article aims to clarify how these various statistical models control for unmeasured time-invariant confounders, helping researchers understand the differences in the statistical models from a causal inference perspective. Assuming that the true data generation model (i.e., causal model) has time-invariant confounders that were not measured, we compared different statistical models (e.g., dynamic panel model and randomintercept cross-lagged panel model) in terms of the conditions under which they can provide a relatively accurate estimate of the target causal estimand. Based on the comparisons and realistic plausibility of these conditions, we made some practical suggestions for researchers to select a statistical model when they are interested in causal inference.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/LM7G9DAV/Murayama and Gfrörer - 2022 - Thinking clearly about time-invariant confounders .pdf}
}

@article{naimi2014,
  title = {Constructing {{Inverse Probability Weights}} for {{Continuous Exposures}}: {{A Comparison}} of {{Methods}}},
  author = {Naimi, Ashley I. and Moodie, Erica E.M. and Auger, Nathalie and Kaufman, Jay S.},
  year = {2014},
  journal = {Epidemiology},
  volume = {25},
  number = {2},
  pages = {292--299},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000053},
  urldate = {2023-09-13},
  abstract = {Inverse probability{\textendash}weighted marginal structural models with binary exposures are common in epidemiology. Constructing inverse probability weights for a continuous exposure can be complicated by the presence of outliers, and the need to identify a parametric form for the exposure and account for nonconstant exposure variance. We explored the performance of various methods to construct inverse probability weights for continuous exposures using Monte Carlo simulation. We generated two continuous exposures and binary outcomes using data sampled from a large empirical cohort. The first exposure followed a normal distribution with homoscedastic variance. The second exposure followed a contaminated Poisson distribution, with heteroscedastic variance equal to the conditional mean. We assessed six methods to construct inverse probability weights using: a normal distribution, a normal distribution with heteroscedastic variance, a truncated normal distribution with heteroscedastic variance, a gamma distribution, a t distribution (1,3, and 5 degrees of freedom), and a quantile binning approach (based on 10, 15, and 20 exposure categories). We estimated the marginal odds ratio for a single-unit increase in each simulated exposure in a regression model weighted by the inverse probability weights constructed using each approach, and then computed the bias and mean squared error for each method. For the homoscedastic exposure, the standard normal, gamma, and quantile binning approaches performed best. For the heteroscedastic exposure, the quantile binning, gamma, and heteroscedastic normal approaches performed best. Our results suggest that the quantile binning approach is a simple and versatile way to construct inverse probability weights for continuous exposures.},
  file = {/Users/pepijnvink/Zotero/storage/4ISH2UDH/Naimi et al. - 2014 - Constructing Inverse Probability Weights for Conti.pdf}
}

@book{pearl2019,
  title = {The {{Book}} of {{Why}}: {{The New Science}} of {{Cause}} and {{Effect}}},
  author = {Pearl, Judea and Mackenzie, Dana},
  year = {2019},
  publisher = {{Penguin Books UK}}
}

@book{R,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  year = {2022},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}}
}

@article{robins2000,
  title = {Marginal {{Structural Models}} and {{Causal Inference}} in {{Epidemiology}}},
  author = {Robins, James M. and Hern{\'a}n, Miguel {\'A}ngel and Brumback, Babette},
  year = {2000},
  journal = {Epidemiology},
  volume = {11},
  number = {5},
  pages = {550--560},
  issn = {1044-3983},
  abstract = {In observational studies with exposures or treatments that vary over time, standard approaches for adjustment of confounding are biased when there exist time-dependent confounders that are also affected by previous treatment. This paper introduces marginal structural models, a new class of causal models that allow for improved adjustment of confounding in those situations. The parameters of a marginal structural model can be consistently estimated using a new class of estimators, the inverse-probability-of-treatment weighted estimators.},
  file = {/Users/pepijnvink/Zotero/storage/STG89R6W/Robins et al. - 2000 - Marginal Structural Models and Causal Inference in.pdf}
}

@article{rohrer2023,
  title = {These {{Are Not}} the {{Effects You Are Looking}} for: {{Causality}} and the {{Within-}}/{{Between-Persons Distinction}} in {{Longitudinal Data Analysis}}},
  shorttitle = {These {{Are Not}} the {{Effects You Are Looking}} For},
  author = {Rohrer, Julia M. and Murayama, Kou},
  year = {2023},
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {6},
  number = {1},
  pages = {251524592211408},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/25152459221140842},
  abstract = {In psychological science, researchers often pay particular attention to the distinction between within- and betweenpersons relationships in longitudinal data analysis. Here, we aim to clarify the relationship between the within- and between-persons distinction and causal inference and show that the distinction is informative but does not play a decisive role in causal inference. Our main points are threefold. First, within-persons data are not necessary for causal inference; for example, between-persons experiments can inform about (average) causal effects. Second, within-persons data are not sufficient for causal inference; for example, time-varying confounders can lead to spurious within-persons associations. Finally, despite not being sufficient, within-persons data can be tremendously helpful for causal inference. We provide pointers to help readers navigate the more technical literature on longitudinal models and conclude with a call for more conceptual clarity: Instead of letting statistical models dictate which substantive questions researchers ask, researchers should start with well-defined theoretical estimands, which in turn determine both study design and data analysis.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/NUQBRKQT/Rohrer and Murayama - 2023 - These Are Not the Effects You Are Looking for Cau.pdf}
}

@article{schafer2008a,
  title = {Average Causal Effects from Nonrandomized Studies: {{A}} Practical Guide and Simulated Example.},
  shorttitle = {Average Causal Effects from Nonrandomized Studies},
  author = {Schafer, Joseph L. and Kang, Joseph},
  year = {2008},
  journal = {Psychological Methods},
  volume = {13},
  number = {4},
  pages = {279--313},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0014268},
  urldate = {2023-12-21},
  abstract = {In a well-designed experiment, random assignment of participants to treatments makes causal inference straightforward. However, if participants are not randomized (as in observational study, quasi-experiment, or nonequivalent control-group designs), group comparisons may be biased by confounders that influence both the outcome and the alleged cause. Traditional analysis of covariance, which includes confounders as predictors in a regression model, often fails to eliminate this bias. In this article, the authors review Rubin's definition of an average causal effect (ACE) as the average difference between potential outcomes under different treatments. The authors distinguish an ACE and a regression coefficient. The authors review 9 strategies for estimating ACEs on the basis of regression, propensity scores, and doubly robust methods, providing formulas for standard errors not given elsewhere. To illustrate the methods, the authors simulate an observational study to assess the effects of dieting on emotional distress. Drawing repeated samples from a simulated population of adolescent girls, the authors assess each method in terms of bias, efficiency, and interval coverage. Throughout the article, the authors offer insights and practical guidance for researchers who attempt causal inference with observational data.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/EBCITYTH/Schafer and Kang - 2008 - Average causal effects from nonrandomized studies.pdf}
}

@misc{schuurman2023,
  type = {Preprint},
  title = {A "{{Within}}/{{Between Problem}}" {{Primer}}: {{About}} ({{Not}}) {{Separating Within-Person Variance}} and {{Between-Person Variance}} in {{Psychology}}.},
  shorttitle = {A "{{Within}}/{{Between Problem}}" {{Primer}}},
  author = {Schuurman, No{\'e}mi Katalin},
  year = {2023},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/7zgkx},
  abstract = {Whenever we measure a psychological variable for multiple persons we typically capture both stable differences between persons, resulting in ``betweenperson variance'', and fluctuations within a person over time, resulting in ``within-person variance''. Both types of variance are of key interest to psychology: Stable differences between persons are the main interest in psychological research on, for example, traits and risk factors. Variation in variables over time are the main interest in studies that focus on psychological processes, change, and development.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/NRMXIDWQ/Schuurman - 2023 - A WithinBetween Problem Primer About (Not) Sep.pdf}
}

@article{shojaie2022,
  title = {Granger {{Causality}}: {{A Review}} and {{Recent Advances}}},
  shorttitle = {Granger {{Causality}}},
  author = {Shojaie, Ali and Fox, Emily B.},
  year = {2022},
  journal = {Annual Review of Statistics and Its Application},
  volume = {9},
  number = {1},
  pages = {289--319},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-040120-010930},
  abstract = {Introduced more than a half-century ago, Granger causality has become a popular tool for analyzing time series data in many application domains, from economics and finance to genomics and neuroscience. Despite this popularity, the validity of this framework for inferring causal relationships among time series has remained the topic of continuous debate. Moreover, while the original definition was general, limitations in computational tools have constrained the applications of Granger causality to primarily simple bivariate vector autoregressive processes. Starting with a review of early developments and debates, this article discusses recent advances that address various shortcomings of the earlier approaches, from models for high-dimensional time series to more recent developments that account for nonlinear and non-Gaussian observations and allow for subsampled and mixed-frequency time series.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/3FXYP8UW/Shojaie and Fox - 2022 - Granger Causality A Review and Recent Advances.pdf}
}

@article{streeter2017,
  title = {Adjusting for Unmeasured Confounding in Nonrandomized Longitudinal Studies: A Methodological Review},
  shorttitle = {Adjusting for Unmeasured Confounding in Nonrandomized Longitudinal Studies},
  author = {Streeter, Adam J. and Lin, Nan Xuan and Crathorne, Louise and Haasova, Marcela and Hyde, Christopher and Melzer, David and Henley, William E.},
  year = {2017},
  journal = {Journal of Clinical Epidemiology},
  volume = {87},
  pages = {23--34},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2017.04.022},
  abstract = {Objectives Motivated by recent calls to use electronic health records for research, we reviewed the application and development of methods for addressing the bias from unmeasured confounding in longitudinal data. Study Design and Setting Methodological review of existing literature. We searched MEDLINE and EMBASE for articles addressing the threat to causal inference from unmeasured confounding in nonrandomized longitudinal health data through quasi-experimental analysis. Results Among the 121 studies included for review, 84 used instrumental variable analysis (IVA), of which 36 used lagged or historical instruments. Difference-in-differences (DiD) and fixed effects (FE) models were found in 29 studies. Five of these combined IVA with DiD or FE to try to mitigate for time-dependent confounding. Other less frequently used methods included prior event rate ratio adjustment, regression discontinuity nested within pre-post studies, propensity score calibration, perturbation analysis, and negative control outcomes. Conclusion Well-established econometric methods such as DiD and IVA are commonly used to address unmeasured confounding in nonrandomized longitudinal studies, but researchers often fail to take full advantage of available longitudinal information. A range of promising new methods have been developed, but further studies are needed to understand their relative performance in different contexts before they can be recommended for widespread use.},
  keywords = {Electronic health records,Longitudinal,Method review,Observational data,Unmeasured confounding,Unobserved confounding},
  file = {/Users/pepijnvink/Zotero/storage/BWLRCFDV/Streeter et al. - 2017 - Adjusting for unmeasured confounding in nonrandomi.pdf;/Users/pepijnvink/Zotero/storage/D5T4XE5M/S0895435616303341.html}
}

@article{thoemmes2016,
  title = {A {{Primer}} on {{Inverse Probability}} of {{Treatment Weighting}} and {{Marginal Structural Models}}},
  author = {Thoemmes, Felix and Ong, Anthony D.},
  year = {2016},
  month = feb,
  journal = {Emerging Adulthood},
  volume = {4},
  number = {1},
  pages = {40--59},
  publisher = {{SAGE Publications Inc}},
  issn = {2167-6968},
  doi = {10.1177/2167696815621645},
  urldate = {2024-01-03},
  abstract = {Emerging adulthood researchers are often interested in the effects of developmental tasks. The majority of transitions that occur during the period of early/emerging adulthood are not randomized; therefore, their effects on developmental trajectories are subject to potential bias due to confounding. Traditionally, confounding has been addressed using regression adjustment; however, there are viable alternatives, such as propensity score matching and inverse probability of treatment weighting. Propensity scores are probabilities of selecting treatment given values on observed covariates. Inverse probability of treatment weights are also based on estimated probabilities of treatment selection and can be used to create so-called pseudo-populations in which confounders and treatment are unrelated to each other. In longitudinal models, such weighting can occur at multiple time points. This article provides a primer on these weighting methods and illustrates their application to studies of emerging adulthood. We provide annotated computer code for both SPSS and R, for both binary and continuous treatments.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/ZFUZA2WB/Thoemmes and Ong - 2016 - A Primer on Inverse Probability of Treatment Weigh.pdf}
}

@article{usami2019,
  title = {A Unified Framework of Longitudinal Models to Examine Reciprocal Relations.},
  author = {Usami, Satoshi and Murayama, Kou and Hamaker, Ellen L.},
  year = {2019},
  journal = {Psychological Methods},
  volume = {24},
  number = {5},
  pages = {637--657},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000210},
  abstract = {Inferring reciprocal effects or causality between variables is a central aim of behavioral and psychological research. To address reciprocal effects, a variety of longitudinal models that include cross-lagged relations have been proposed in different contexts and disciplines. However, the relations between these cross-lagged models have not been systematically discussed in the literature. This lack of insight makes it difficult for researchers to select an appropriate model when analyzing longitudinal data, and some researchers do not even think about alternative cross-lagged models. The present research provides a unified framework that clarifies the conceptual and mathematical similarities and differences between these models. The unified framework shows that existing longitudinal models can be effectively classified based on whether the model posits unique factors and/or dynamic residuals and what types of common factors are used to model changes. The latter is essential to understand how cross-lagged parameters are interpreted. We also present an example using empirical data to demonstrate that there is great risk of drawing different conclusions depending on the cross-lagged models used.},
  langid = {english},
  file = {/Users/pepijnvink/Zotero/storage/2XJ7QMPK/Usami et al. - 2019 - A unified framework of longitudinal models to exam.pdf}
}

@article{usami2021,
  title = {On the {{Differences}} between {{General Cross-Lagged Panel Model}} and {{Random-Intercept Cross-Lagged Panel Model}}: {{Interpretation}} of {{Cross-Lagged Parameters}} and {{Model Choice}}},
  shorttitle = {On the {{Differences}} between {{General Cross-Lagged Panel Model}} and {{Random-Intercept Cross-Lagged Panel Model}}},
  author = {Usami, Satoshi},
  year = {2021},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {28},
  number = {3},
  pages = {331--344},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2020.1821690},
  langid = {english},
  keywords = {to read},
  file = {/Users/pepijnvink/Zotero/storage/CSRGHIM5/Usami - 2021 - On the Differences between General Cross-Lagged Pa.pdf}
}

@article{vanderweele2016,
  title = {Causal Inference and Longitudinal Data: A Case Study of Religion and Mental Health},
  shorttitle = {Causal Inference and Longitudinal Data},
  author = {VanderWeele, Tyler J. and Jackson, John W. and Li, Shanshan},
  year = {2016},
  journal = {Social Psychiatry and Psychiatric Epidemiology},
  volume = {51},
  number = {11},
  pages = {1457--1466},
  issn = {1433-9285},
  doi = {10.1007/s00127-016-1281-9},
  abstract = {We provide an introduction to causal inference with longitudinal data and discuss the complexities of analysis and interpretation when exposures can vary over time.},
  langid = {english},
  keywords = {Causal inference,Confounding,Longitudinal data,Marginal structural models,Religion},
  file = {/Users/pepijnvink/Zotero/storage/8G9XYNJ9/VanderWeele et al. - 2016 - Causal inference and longitudinal data a case stu.pdf}
}

@article{vansteelandt2014,
  title = {On Regression Adjustment for the Propensity Score},
  author = {Vansteelandt, S. and Daniel, R.m.},
  year = {2014},
  journal = {Statistics in Medicine},
  volume = {33},
  number = {23},
  pages = {4053--4072},
  issn = {1097-0258},
  doi = {10.1002/sim.6207},
  abstract = {AbstractPropensity scores are widely adopted in observational research because they enable adjustment for high-dimensional confounders without requiring models for their association with the outcome of interest. The results of statistical analyses based on stratification, matching or inverse weighting by the propensity score are therefore less susceptible to model extrapolation than those based solely on outcome regression models. This is attractive because extrapolation in outcome regression models may be alarming, yet difficult to diagnose, when the exposed and unexposed individuals have very different covariate distributions.Standard regression adjustment for the propensity score forms an alternative to the aforementioned propensity score methods, but the benefits of this are less clear because it still involves modelling the outcome in addition to the propensity score. In this article, we develop novel insights into the properties of this adjustment method. We demonstrate that standard tests of the null hypothesis of no exposure effect (based on robust variance estimators), as well as particular standardised effects obtained from such adjusted regression models, are robust against misspecification of the outcome model when a propensity score model is correctly specified; they are thus not vulnerable to the aforementioned problem of extrapolation. We moreover propose efficient estimators for these standardised effects, which retain a useful causal interpretation even when the propensity score model is misspecified, provided the outcome regression model is correctly specified. Copyright {\textcopyright} 2014 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {causal inference,effect measure,model misspecification,pooling,positivity,propensity score,standardisation,strong confounding},
  file = {/Users/pepijnvink/Zotero/storage/6WPNMXFN/Vansteelandt and Daniel - 2014 - On regression adjustment for the propensity score.pdf;/Users/pepijnvink/Zotero/storage/95IUZZ25/sim.html}
}

@article{zhu2015,
  title = {A {{Boosting Algorithm}} for {{Estimating Generalized Propensity Scores}} with {{Continuous Treatments}}},
  author = {Zhu, Yeying and Coffman, Donna L. and Ghosh, Debashis},
  year = {2015},
  journal = {Journal of Causal Inference},
  volume = {3},
  number = {1},
  pages = {25--40},
  issn = {2193-3685},
  doi = {10.1515/jci-2014-0022},
  abstract = {In this article, we study the causal inference problem with a continuous treatment variable using propensity score-based methods. For a continuous treatment, the generalized propensity score is defined as the conditional density of the treatment-level given covariates (confounders). The dose{\textendash}response function is then estimated by inverse probability weighting, where the weights are calculated from the estimated propensity scores. When the dimension of the covariates is large, the traditional nonparametric density estimation suffers from the curse of dimensionality. Some researchers have suggested a two-step estimation procedure by first modeling the mean function. In this study, we suggest a boosting algorithm to estimate the mean function of the treatment given covariates. In boosting, an important tuning parameter is the number of trees to be generated, which essentially determines the trade-off between bias and variance of the causal estimator. We propose a criterion called average absolute correlation coefficient (AACC) to determine the optimal number of trees. Simulation results show that the proposed approach performs better than a simple linear approximation or L2 boosting. The proposed methodology is also illustrated through the Early Dieting in Girls study, which examines the influence of mothers' overall weight concern on daughters' dieting behavior.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  keywords = {boosting,distance correlation,dose{\textendash}response function,generalized propensity scores,high dimensional},
  file = {/Users/pepijnvink/Zotero/storage/INGJTIQK/Zhu et al. - 2015 - A Boosting Algorithm for Estimating Generalized Pr.pdf}
}
